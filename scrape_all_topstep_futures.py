#!/usr/bin/env python3
"""
Comprehensive CME futures scraper for all TopstepX symbols using Tavily Extract.

This script scrapes all 60+ TopstepX-allowed futures contracts from CME Group
using the Tavily MCP tool for reliable extraction of JavaScript-rendered pages.

Output: futures_roll_data.json with all contract specifications
"""

import json
import re
import time
from typing import Dict, List

from scrape_cme_futures_specs import TOPSTEP_SYMBOLS, get_cme_contract_specs_url


def parse_contract_specs_from_text(text: str, symbol: str) -> Dict:
    """
    Parse contract specifications from extracted HTML/markdown text.

    Looks for key fields:
    - Listed Contracts / Contract Months
    - Termination of Trading / Last Trading Day
    - Settlement Method
    """
    specs = {
        "symbol": symbol,
        "name": TOPSTEP_SYMBOLS.get(symbol, ""),
        "listed_contracts": None,
        "contract_months": None,
        "termination_of_trading": None,
        "last_trading_day": None,
        "settlement_method": None,
    }

    # Split into lines for pattern matching
    lines = text.split("\n")

    for line in lines:
        line_lower = line.lower()

        # Look for "Listed Contracts" row
        if "listed contract" in line_lower and "|" in line:
            # CME tables use | Field | Value | format
            # Find the value part (after first |)
            match = re.search(r"\|\s*listed contracts?\s*\|\s*([^|]+)\s*\|", line, re.IGNORECASE)
            if match:
                value = match.group(1).strip()
                specs["listed_contracts"] = value
                specs["contract_months"] = value

        # Look for "Termination of Trading"
        if "termination of trading" in line_lower and "|" in line:
            match = re.search(r"\|\s*termination of trading\s*\|\s*([^|]+)\s*\|", line, re.IGNORECASE)
            if match:
                value = match.group(1).strip()
                specs["termination_of_trading"] = value
                if not specs["last_trading_day"]:
                    specs["last_trading_day"] = value

        # Look for "Last Trading Day" (alternative field name)
        if "last trading day" in line_lower and "|" in line and not specs["termination_of_trading"]:
            match = re.search(r"\|\s*last trading day\s*\|\s*([^|]+)\s*\|", line, re.IGNORECASE)
            if match:
                value = match.group(1).strip()
                specs["last_trading_day"] = value
                specs["termination_of_trading"] = value

        # Look for "Settlement Method"
        if "settlement method" in line_lower and "|" in line:
            match = re.search(r"\|\s*settlement method\s*\|\s*([^|]+)\s*\|", line, re.IGNORECASE)
            if match:
                value = match.group(1).strip()
                specs["settlement_method"] = value

    return specs


def scrape_batch_with_tavily(symbols: List[str], urls: List[str]) -> List[Dict]:
    """
    Scrape a batch of URLs using Tavily extract.

    NOTE: This is a placeholder - in actual execution, you would call:
    mcp__tavily__tavily_extract with the URLs list

    Returns list of parsed specs dicts.
    """
    print(f"\nüîç Scraping batch: {', '.join(symbols)}")
    print("   URLs:")
    for url in urls:
        print(f"     - {url}")

    # IMPORTANT: When running this script, you need to manually call
    # the Tavily extract tool with these URLs, then parse the results.
    # This script provides the framework.

    print("\n   ‚ö†Ô∏è  Manual step required:")
    print("   Call mcp__tavily__tavily_extract with URLs above")
    print("   Then parse the returned text with parse_contract_specs_from_text()")

    return []


def main():
    """Main scraping workflow."""
    print("=" * 80)
    print("CME Futures Contract Specifications - Complete Scraper")
    print("=" * 80)
    print(f"\nüìã Scraping all {len(TOPSTEP_SYMBOLS)} TopstepX futures contracts")
    print("   Method: Tavily Extract (JavaScript-rendered pages)")
    print("   Source: Official CME contract specifications")
    print()

    # Build URL map
    urls_map = {}
    for symbol in sorted(TOPSTEP_SYMBOLS.keys()):
        url = get_cme_contract_specs_url(symbol)
        if url:
            urls_map[symbol] = url
        else:
            print(f"‚ö†Ô∏è  No URL mapping for {symbol}")

    # Create batches of 3
    batches = []
    symbols_list = list(urls_map.keys())
    for i in range(0, len(symbols_list), 3):
        batch_symbols = symbols_list[i : i + 3]
        batch_urls = [urls_map[s] for s in batch_symbols]
        batches.append((batch_symbols, batch_urls))

    print(f"üì¶ Created {len(batches)} batches of 3 symbols each\n")

    # For actual execution, you would:
    # 1. Call Tavily extract for each batch
    # 2. Parse the results
    # 3. Accumulate specs
    #
    # Example workflow:
    all_specs = []

    for batch_num, (batch_symbols, batch_urls) in enumerate(batches, 1):
        print(f"\n{'='*80}")
        print(f"Batch {batch_num}/{len(batches)}: {', '.join(batch_symbols)}")
        print(f"{'='*80}")

        # This is where you'd call Tavily
        # For now, just show what needs to be done
        for symbol, url in zip(batch_symbols, batch_urls):
            print(f"  {symbol}: {url}")

        print("\n  ‚è∏Ô∏è  Waiting for Tavily extract results...")
        print("     After getting results, parse with:")
        print("     parse_contract_specs_from_text(result_text, symbol)")

        # Simulate delay between batches
        if batch_num < len(batches):
            time.sleep(2)

    # Save results
    output_file = "futures_roll_data.json"
    with open(output_file, "w") as f:
        json.dump(all_specs, f, indent=2)

    print("\n" + "=" * 80)
    print("‚úÖ Scraping framework ready")
    print(f"üíæ Results will be saved to: {output_file}")
    print("=" * 80)

    print("\nüìù Next Steps:")
    print("   1. Run this script to see the batch structure")
    print("   2. For each batch, call mcp__tavily__tavily_extract with the URLs")
    print("   3. Parse results using parse_contract_specs_from_text()")
    print("   4. Accumulate all specs into futures_roll_data.json")
    print()
    print("   Or: Integrate with Claude Code to automate Tavily calls")


if __name__ == "__main__":
    main()
