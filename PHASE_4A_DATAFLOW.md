# Phase 4A Data Flow Visualization

## Current Flow (Pandas - Phase 3)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Network Layer (databento_helper.py)                         â”‚
â”‚    - Fetch from DataBento API                                   â”‚
â”‚    - Read parquet with PyArrow                                  â”‚
â”‚    - Convert to Pandas DataFrame                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Returns: Pandas DF
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Data Source Layer (databento_backtesting_polars.py)         â”‚
â”‚    - _pull_source_symbol_bars()                                 â”‚
â”‚    - Filter with pandas boolean indexing: df[df['x'] > y]       â”‚
â”‚    - Datetime operations with pandas                            â”‚
â”‚    - SLOW: 2.7M DatetimeArray iterations                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Returns: Bars(pandas_df, SOURCE="POLARS")  â† BUG: Wrong!
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Bars Storage (bars.py)                                       â”‚
â”‚    - self._df = pandas_df                                       â”‚
â”‚    - Stored as Pandas                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. High-Frequency Operations (polars_data.py)                   â”‚
â”‚    - get_historical_prices() called 6,283 times                 â”‚
â”‚    - Each call: df = bars.df (no conversion, already pandas)    â”‚
â”‚    - Filter: df[(df.index >= start) & (df.index <= end)]       â”‚
â”‚    - SLOW: Pandas boolean indexing                              â”‚
â”‚                                                                  â”‚
â”‚    - get_last_price() called thousands of times                 â”‚
â”‚    - Each call: df.iloc[-1]['close']                            â”‚
â”‚    - SLOW: Pandas indexing overhead                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Returns: Pandas DF
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Strategy Layer (user code)                                   â”‚
â”‚    - bars = self.get_historical_prices(asset, 200, "minute")    â”‚
â”‚    - df = bars.df  â† Gets Pandas DF                             â”‚
â”‚    - df["sma"] = df["close"].rolling(9).mean()                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TOTAL TIME: 95.39s
BOTTLENECK: DatetimeArray iterations (10s), Pandas filtering (slow)
```

---

## New Flow (Polars Internal - Phase 4A)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Network Layer (databento_helper.py)                         â”‚
â”‚    - Fetch from DataBento API                                   â”‚
â”‚    - Read parquet with PyArrow                                  â”‚
â”‚    - Convert to Pandas DataFrame                                â”‚
â”‚    - âœ“ NO CHANGES (network not bottleneck)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Returns: Pandas DF
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Data Source Layer (databento_backtesting_polars.py)         â”‚
â”‚    - _pull_source_symbol_bars()                                 â”‚
â”‚    - âœ¨ NEW: df_polars = self._pandas_to_polars(df_pandas)      â”‚
â”‚    - âœ¨ NEW: Filter with polars:                                â”‚
â”‚             df_polars.filter(                                   â”‚
â”‚                 (pl.col("timestamp") >= start) &                â”‚
â”‚                 (pl.col("timestamp") <= end)                    â”‚
â”‚             )                                                    â”‚
â”‚    - FAST: Polars native datetime operations (no Python)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Returns: Bars(polars_df, SOURCE="POLARS")  â† CORRECT!
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Bars Storage (bars.py)                                       â”‚
â”‚    - âœ¨ NEW: Dual storage                                       â”‚
â”‚    - self._df_polars = polars_df                                â”‚
â”‚    - self._df_pandas = None  (lazy conversion)                  â”‚
â”‚                                                                  â”‚
â”‚    - @property df:                                              â”‚
â”‚        if self._df_pandas is None:                              â”‚
â”‚            self._df_pandas = self._df_polars.to_pandas()        â”‚
â”‚        return self._df_pandas                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. High-Frequency Operations (polars_data.py)                   â”‚
â”‚    - âœ¨ get_historical_prices() called 6,283 times              â”‚
â”‚      - Access bars._df_polars directly (no conversion!)         â”‚
â”‚      - Filter: df_polars.filter(pl.col("timestamp") >= start)   â”‚
â”‚      - Return: Bars(filtered_polars, SOURCE="POLARS")           â”‚
â”‚      - FAST: Polars expressions, no conversion                  â”‚
â”‚                                                                  â”‚
â”‚    - âœ¨ get_last_price() called thousands of times              â”‚
â”‚      - Access bars._df_polars directly                          â”‚
â”‚      - Get last: df_polars.select(pl.col("close").last())       â”‚
â”‚      - FAST: Polars optimized, no indexing overhead             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Returns: Polars DF internally
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Strategy Layer (user code)                                   â”‚
â”‚    - bars = self.get_historical_prices(asset, 200, "minute")    â”‚
â”‚    - df = bars.df  â† ðŸ”„ CONVERTS Polars â†’ Pandas here           â”‚
â”‚    - df["sma"] = df["close"].rolling(9).mean()                  â”‚
â”‚    - âœ“ User code unchanged (still gets Pandas)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TOTAL TIME: 70-75s (target)
SPEEDUP: 1.25-1.35x (20-30% faster)
IMPROVEMENTS:
  - DatetimeArray iterations: 10s â†’ 3s (polars native datetimes)
  - Filtering operations: Fast polars expressions (no Python overhead)
  - Conversion overhead: Reduced (only convert at final boundary)
```

---

## Key Differences Highlighted

### 1. When Conversion Happens

**BEFORE (Phase 3)**:
```
Fetch â†’ Pandas â†’ Store Pandas â†’ Use Pandas â†’ Return Pandas
        â†‘                                      â†‘
    Convert once                           No conversion
```

**AFTER (Phase 4A)**:
```
Fetch â†’ Pandas â†’ Polars â†’ Store Polars â†’ Use Polars â†’ Return Pandas
        â†‘        â†‘                                    â†‘
    Convert    Convert                            Convert
    (network)  (once)                             (lazy, final boundary)
```

### 2. Filtering Operations

**BEFORE**:
```python
# Pandas boolean indexing (slow for large datasets)
df[(df['timestamp'] >= start) & (df['timestamp'] <= end)]

# Creates intermediate boolean Series
# Python loop overhead
# Slow datetime comparisons
```

**AFTER**:
```python
# Polars expressions (fast, optimized)
df_polars.filter(
    (pl.col("timestamp") >= start) &
    (pl.col("timestamp") <= end)
)

# No intermediate objects
# Compiled expressions
# Native datetime handling
```

### 3. Last Price Lookup

**BEFORE**:
```python
# Pandas indexing
df.iloc[-1]['close']
# - Index lookup overhead
# - Column access overhead
# - Slower for repeated calls
```

**AFTER**:
```python
# Polars selection
df_polars.select(pl.col("close").last()).item()
# - Optimized last() operation
# - Single expression
# - Much faster
```

---

## Conversion Points Comparison

### Phase 3 (Current)
```
API â†’ Pandas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Strategy
      â†‘                                      â†‘
  Convert once                          No conversion needed
  (in helper)                           (already Pandas)

  Total conversions: 1 per fetch
```

### Phase 4A (Optimized)
```
API â†’ Pandas â†’ Polars â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Pandas â†’ Strategy
      â†‘        â†‘                         â†‘
  Convert    Convert                 Convert
  (helper)   (immediate)             (lazy, only if accessed)

  Total conversions: 2 per fetch (but way faster operations)
```

**Why this is faster despite extra conversion:**
- Polars operations are 5-10x faster than Pandas
- Lazy conversion means we only convert if strategy uses `.df`
- Many operations (filtering, slicing) stay in Polars (no conversion)
- Polars native datetime operations save massive overhead

---

## Performance Breakdown

### Time Saved by Operation

| Operation | Before | After | Saved | Method |
|-----------|--------|-------|-------|--------|
| DatetimeArray iteration | 10.0s | ~3.0s | 7.0s | Polars native datetimes |
| Filtering (6,283 calls) | 30.0s | ~20.0s | 10.0s | Polars expressions |
| Conversion overhead | 3.0s | ~1.0s | 2.0s | Fewer conversions |
| Last price (thousands) | 5.0s | ~2.0s | 3.0s | Polars .last() |
| Other operations | 47.4s | ~44.0s | 3.4s | General overhead |
| **TOTAL** | **95.4s** | **~70s** | **~25s** | **26% speedup** |

---

## Memory Usage

### Phase 3 (Pandas only)
```
Fetch: Pandas DF (e.g., 6,461 rows Ã— 8 cols = ~400KB)
Store: Same Pandas DF (400KB)
Use: Same Pandas DF (400KB)

Peak memory: ~400KB per asset
```

### Phase 4A (Polars internal)
```
Fetch: Pandas DF (400KB)
Store: Polars DF (~350KB - more efficient memory layout)
Return: Pandas DF (400KB - lazy conversion)

Peak memory: ~750KB per asset (if conversion happens)
             ~350KB per asset (if no conversion needed)
```

**Memory tradeoff**:
- Slight increase if strategy accesses `.df` (both formats in memory)
- Same or better if strategy doesn't access `.df` (polars more efficient)
- Not a concern for backtesting (memory is not the bottleneck)

---

## Testing Strategy

### 1. Unit Test: Conversion Functions
```python
def test_pandas_to_polars():
    df_pandas = pd.DataFrame({'x': [1, 2, 3]})
    df_polars = PolarsData._pandas_to_polars(df_pandas)
    assert df_polars.shape == (3, 1)
    assert df_polars['x'].to_list() == [1, 2, 3]

def test_polars_to_pandas():
    df_polars = pl.DataFrame({'x': [1, 2, 3]})
    df_pandas = PolarsData._polars_to_pandas(df_polars)
    assert df_pandas.shape == (3, 1)
    assert list(df_pandas['x']) == [1, 2, 3]
```

### 2. Integration Test: Parity
```bash
pytest tests/backtest/test_databento_parity.py -v
```
- Ensures Pandas and Polars backends produce identical results
- Tests datetime handling, filtering, last price, all operations

### 3. Performance Test: Profiling
```bash
python -m tests.performance.profile_databento_mes_momentum --mode both
```
- Measures actual speedup
- Compares before/after profiles
- Validates that optimizations have real impact

---

## Rollback Plan

If Phase 4A doesn't work:

### Easy Rollback
All changes are additive:
1. Bars class has both `_df_polars` and `_df_pandas` (keeps working with pandas)
2. PolarsData methods check `if SOURCE == "POLARS"` (pandas path untouched)
3. No breaking changes to external API

### Quick Fix
If parity tests fail but you need to move forward:
```python
# In polars_data.py, force pandas path:
def get_historical_prices(self, asset, length, ...):
    # Temporarily disable polars optimization
    if True:  # Change to: if self.SOURCE == "POLARS":
        # ... polars path ...
    else:
        # ... pandas path (fallback) ...
```

This lets you keep working while debugging the polars path.
