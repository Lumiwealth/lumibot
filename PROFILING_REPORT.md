# Lumibot GC Futures Performance Profiling Report
**Date:** 2025-11-01  
**Profiler:** YAPPI (Wall-clock time)  
**Strategy:** examples/gc_futures_optimized.py  
**Data Source:** DataBento (Polars)

---

## Executive Summary

‚úÖ **Confirmed O(n¬≤) performance degradation** in gc_futures_optimized.py backtest  
‚ö†Ô∏è **Critical Finding:** Per-call execution time increases dramatically with backtest duration  
üí° **Early Exit Success:** Detected O(n¬≤) behavior in 4 minutes instead of 50+ minutes

### The Problem
- **1-month backtest:** ~88 seconds (baseline performance)
- **10-month backtest:** **Expected ~15 min** (linear scaling), **Actual ~50+ min** (3.3x slower)
- **Root Cause:** Non-linear performance degradation confirmed via systematic profiling

---

## Profiling Methodology

### Phase 0: Cache Impact Analysis
- **Cold run (no cache):** 88.20s, 6,120 iterations, 69.4 iter/sec
- **Warm run (with cache):** 78.45s, 6,120 iterations
- **Cache impact:** 11.1% speedup (moderate, not the primary issue)

### Phase 1: Progressive Time Window Analysis
Ran systematic profiling across different backtest durations:
- **1-week runs:** 4 samples, ~25-32 seconds each
- **1-month runs:** 3 samples, 78-162 seconds each  
- **3-month early exit:** 120s timeout, detected degradation
- **10-month early exit:** 120s timeout, **confirmed severe O(n¬≤) behavior**

### Early Exit Innovation
Used signal.SIGALRM timeout mechanism to:
- Stop long-running tests after 120 seconds
- Capture partial profiling data
- Compare per-call timing vs baseline
- **Result:** 95% time savings while detecting O(n¬≤) pattern

---

## Critical Findings

### 1. Main Trading Iteration Degradation (7.8x slower)

| Metric | Baseline (1-month) | 10-Month Early Exit | Degradation |
|--------|-------------------|---------------------|-------------|
| Per-call time | 11.68 ms | **91.41 ms** | **7.83x** |
| Total time | 71.48s | 116.45s | 1.63x |
| Iterations | 6,120 | 1,274 | -- |

**Function:** `GCFuturesOptimized.on_trading_iteration`

### 2. Historical Price Fetching Degradation (8.0x slower)

| Metric | Baseline | 10-Month Early | Degradation |
|--------|----------|----------------|-------------|
| Per-call time | 11.23 ms | **90.32 ms** | **8.04x** |
| Total time | 69.26s | 115.34s | 1.67x |

**Function:** `DataBentoDataBacktestingPolars.get_historical_prices`

### 3. DataFrame Operations - Smoking Gun üéØ

| Operation | Baseline (ms/call) | 10-Month (ms/call) | Degradation | Calls |
|-----------|-------------------|-------------------|-------------|-------|
| **sort_index** | **0.082** | **18.745** | **228.60x** üî• | 1,278 |
| **concatenate_managers** | 0.101 | 2.441 | **24.11x** | 1,286 |
| **concat** | 0.243 | 3.247 | **13.35x** | 1,288 |
| **drop** | 0.399 | 3.888 | **9.74x** | 1,277 |
| **reset_index** | 0.299 | 2.016 | **6.73x** | 2,555 |
| **filter** | 0.241 | 0.989 | **4.10x** | 6,242 |

**Key Insight:** `DataFrame.sort_index` shows 228x per-call degradation, strongest indicator of O(n¬≤) behavior

### 4. Progression Analysis: 3-Month vs 10-Month

| Function | 3-Month Ratio | 10-Month Ratio | Acceleration |
|----------|---------------|----------------|--------------|
| on_trading_iteration | 3.07x | **6.73x** | 2.2x worse |
| GCFuturesOptimized iteration | 2.97x | **7.83x** | 2.6x worse |
| func_output | 2.97x | **7.81x** | 2.6x worse |
| Functions with 50%+ slowdown | 731 | **984** | +35% |

**Non-linear acceleration confirms O(n¬≤) complexity**

---

## Root Cause Analysis

### Primary Suspect: Data Structure Accumulation
**Location:** examples/gc_futures_optimized.py

#### Line 122: Initialization
```python
self._bars_dataframes = []  # List of DataFrames with 1-minute bars
```

#### Lines 275-279: Accumulation Pattern (O(n) growth)
```python
if not hasattr(self, '_bars_dataframes'):
    self._bars_dataframes = []

self._bars_dataframes.append(bars.df.copy())  # Grows every iteration
```

#### Lines 427-430: O(n¬≤) Operations
```python
df_combined = pd.concat(self._bars_dataframes, ignore_index=False)  # O(n)
# ...
df_combined = df_combined.sort_index()  # O(n log n) on growing data
```

### Complexity Analysis
- After N iterations: `_bars_dataframes` contains N DataFrames
- `pd.concat()` on N DataFrames: O(N) time
- `sort_index()` on combined data (N √ó bars_per_df rows): O(N log N)
- **If called every iteration:** O(N¬≤) for concat, O(N¬≤ log N) for sort
- **Evidence:** sort_index called 1,278 times in 10-month early exit (~1 per iteration)

---

## Performance Impact Quantification

### Time Savings from Early Exit
- **Without early exit:** Would need to run full 10-month test (~50 minutes)
- **With early exit:** Detected O(n¬≤) in 2 minutes (120s timeout)
- **Time saved:** **95%** (48 minutes saved)

### Projected Full-Duration Impact
Based on early exit degradation trajectory:
- **Expected 10-month time (linear):** ~880 seconds (14.7 min)
- **Actual projected 10-month time:** ~3,000+ seconds (50+ min)
- **Degradation factor:** 3.4x slower than linear expectation

---

## Recommended Fixes

### Fix 1: Incremental DataFrame Maintenance
Instead of appending and re-concatenating every time:
```python
# Initialize once
self._bars_combined = None

# In on_trading_iteration:
if self._bars_combined is None:
    self._bars_combined = bars.df.copy()
else:
    # Incremental concatenation (O(1) amortized with proper implementation)
    self._bars_combined = pd.concat([self._bars_combined, bars.df], ignore_index=False)
    # Only sort when needed for plotting (once at end)
```

### Fix 2: Use Pre-sorted Data Structure
```python
# Polars is already fast - leverage it
self._bars_polars = pl.DataFrame()  # Use Polars for accumulation
# Convert to Pandas only once for plotting
```

### Fix 3: Limit Accumulation Scope
```python
# Only collect bars for plotting purposes
# Use a deque with maxlen to prevent unlimited growth
from collections import deque
self._bars_samples = deque(maxlen=1000)  # Keep only last 1000 bars for plotting
```

### Fix 4: Lazy Evaluation
```python
# Don't process plotting data during iteration
# Collect raw data, process only at the end
self._bars_raw = []  # Collect only what's needed
# Process in _plot_from_samples() (called once)
```

---

## Validation Plan

### Before Fix Benchmark
```bash
python -m profiler.runner --run full-2025-01-01_10-31 --timeout 120
# Current result: 91.4ms per iteration at 120s mark
```

### After Fix Benchmark
```bash
# Apply recommended fix
python -m profiler.runner --run full-2025-01-01_10-31 --timeout 120
# Expected: <15ms per iteration (similar to baseline)
# Success criteria: <2x baseline per-call time
```

### Full Run Validation
```bash
# After confirming early exit improvement
python -m profiler.runner --run full-2025-01-01_10-31
# Expected completion time: <20 minutes (vs current 50+ min)
```

---

## Profiling Infrastructure

### Tools Created
1. **profiler/runner.py** - YAPPI-instrumented backtest executor
2. **profiler/compare_early_exit.py** - Early exit vs baseline comparison
3. **profiler/config.py** - JSON-based profiling plan management
4. **profiler/utils.py** - Helper functions for timing and formatting

### Key Features
- **Early exit timeout:** signal.SIGALRM-based automatic stop
- **JSON result tracking:** profiling_plan.json stores all run data
- **CSV export:** Function and thread statistics in CSV format
- **pstat export:** For compatibility with pstats analysis tools

### Files Generated
```
profiling/
‚îú‚îÄ‚îÄ profiling_plan.json              # Run metadata and results
‚îú‚îÄ‚îÄ phase0-cold-2025-01.funcs.wall.csv
‚îú‚îÄ‚îÄ phase0-cold-2025-01.threads.wall.csv
‚îú‚îÄ‚îÄ phase0-cold-2025-01.wall.pstat
‚îú‚îÄ‚îÄ full-2025-01-01_10-31.early.funcs.wall.csv
‚îú‚îÄ‚îÄ full-2025-01-01_10-31.early.threads.wall.csv
‚îú‚îÄ‚îÄ full-2025-01-01_10-31.early.wall.pstat
‚îî‚îÄ‚îÄ ... (11 runs total)
```

---

## Conclusions

1. ‚úÖ **O(n¬≤) behavior conclusively proven** via systematic profiling
2. ‚úÖ **Root cause identified:** DataFrame accumulation pattern in gc_futures_optimized.py:275-279, 427-430
3. ‚úÖ **Early exit profiling validated:** 95% time savings while detecting degradation
4. ‚úÖ **Multiple performance bottlenecks quantified:** sort_index (228x), concatenate_managers (24x), concat (13x)
5. ‚ö†Ô∏è **Immediate action required:** Apply recommended fixes to restore linear scaling
6. üéØ **Success metric:** Reduce 10-month backtest from 50+ min to <20 min (~60% improvement)

---

## Next Steps

1. **Immediate:** Apply Fix 1 (incremental DataFrame maintenance)
2. **Validate:** Run early exit profiling to confirm improvement
3. **Full test:** Run complete 10-month backtest to verify linear scaling
4. **Monitor:** Track iteration rates across different duration windows
5. **Document:** Update gc_futures_optimized.py with performance best practices

**Report Generated:** 2025-11-01 20:56:00 UTC  
**Profiler:** Claude Code + YAPPI  
**Total Profiling Time:** ~45 minutes (vs 120+ min without early exit)
